{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Index(['Age', 'Centroid1', 'FirstAxis3', 'SecondAxis1', 'ThirdAxis1',\n",
      "       'ThirdAxis2', 'kurtosis', 'entropy'],\n",
      "      dtype='object')\n",
      "WARNING:tensorflow:From /home/navodini/py3_kernel/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/navodini/py3_kernel/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navodini/py3_kernel/lib/python3.5/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00541: early stopping\n",
      "Train: 0.585, Test: 0.600\n",
      "8\n",
      "Index(['FirstAxis3', 'SecondAxis1', 'ThirdAxis1', 'Eigen2', 'bb3', 'extent',\n",
      "       'diameter', 'f6'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navodini/py3_kernel/lib/python3.5/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00740: early stopping\n",
      "Train: 0.521, Test: 0.400\n",
      "8\n",
      "Index(['Age', 'MinorAxisLength', 'FirstAxis3', 'SecondAxis1', 'SecondAxis2',\n",
      "       'ThirdAxis1', 'kurtosis', 'histogram'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navodini/py3_kernel/lib/python3.5/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00201: early stopping\n",
      "Train: 0.553, Test: 0.500\n",
      "8\n",
      "Index(['Age', 'FirstAxis2', 'FirstAxis3', 'SecondAxis1', 'ThirdAxis1',\n",
      "       'kurtosis', 'diameter', 'f1'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navodini/py3_kernel/lib/python3.5/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03964: early stopping\n",
      "Train: 0.681, Test: 0.600\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.svm as svm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import StandardScaler,Normalizer\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from imblearn.datasets import make_imbalance\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "df = pd.DataFrame(columns=['num_features','fold1','fold2','fold3','fol4'])\n",
    "#for i in range(1,80):\n",
    "#for i in range(1,25):\n",
    "#Accuracy = np.array(i)\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        #print(m.weight)\n",
    "        torch.nn.init.constant_(m.weight,0.1)\n",
    "        m.bias.data.fill_(0.001)\n",
    "# for i in range(1,25):\n",
    "Accuracy = np.array(8)\n",
    "for fold in range(1,5):\n",
    "    features = pd.read_csv('ICH_Features.csv',header=0)\n",
    "    OS_train = pd.read_csv('Fold'+str(fold)+'/Train_dir.txt',header = None, dtype=str)\n",
    "    OS_train.columns = ['ID','OS']\n",
    "    OS_valid = pd.read_csv('Fold'+str(fold)+'/Val_Dir.txt',header = None, dtype=str)\n",
    "    OS_valid.columns = ['ID','OS']\n",
    "    features['ID']=features['ID'].str.replace('ct1','')\n",
    "    train = pd.merge(features, OS_train, how='right', on='ID')\n",
    "    test =  pd.merge(features, OS_valid, how='right', on='ID')\n",
    "    norm_wihtout = [col for col in train.columns if col not in ['ID','GCS','Onset','OS']]\n",
    "    #norm_valid = [col for col in test.columns if col not in ['ID','GCS','Onset','OS']]\n",
    "    scaler = StandardScaler()\n",
    "    train_ss = scaler.fit_transform(train[norm_wihtout])\n",
    "    test_ss = scaler.transform(test[norm_wihtout])\n",
    "    train[norm_wihtout] = train_ss\n",
    "    test[norm_wihtout] = test_ss\n",
    "    #train = train.assign(norm_train.values = train_ss)\n",
    "    col_withoutID = [col for col in train.columns if col not in ['ID','OS']]\n",
    "    #train_X , train_y = make_imbalance(train[col_withoutID],train['OS'].values.astype(int),sampling_strategy={0:50 , 1:40 },random_state=42)\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_res, y_res = ros.fit_resample(train[col_withoutID], train['OS'].values.astype(int))\n",
    "    train_X = pd.DataFrame(X_res,columns = col_withoutID)\n",
    "    train_y = pd.DataFrame(y_res, columns = ['OS'])\n",
    "    num_features = 8\n",
    "    estimator = svm.SVC(kernel=\"linear\", C=1)\n",
    "    print(num_features)\n",
    "    rfe=RFE(estimator,  n_features_to_select=num_features,step=1)\n",
    "    rfe.fit(train_X,train_y)\n",
    "    ranking_RFE=rfe.ranking_\n",
    "    indices=np.where(ranking_RFE==1)\n",
    "    indices = list(indices[0])\n",
    "    data_RFE=train_X.iloc[:,indices]\n",
    "    valid_RFE = test[col_withoutID].iloc[:,indices]\n",
    "    print(data_RFE.columns)\n",
    "    #y_train = to_categorical(train_y.values.astype(int))\n",
    "    #y_test = to_categorical(test['OS'])\n",
    "#     lb = preprocessing.LabelBinarizer()\n",
    "#     lb.fit(train['OS'].values.astype(int))\n",
    "#     y_test=lb.transform(test['OS'].values.astype(int))\n",
    "#     y_train=lb.transform(train['OS'].values.astype(int))\n",
    "#         model = Sequential()\n",
    "#         model.add(Dense(29, input_dim=num_features, activation='relu',kernel_initializer = keras.initializers.Constant(value=0.01)))\n",
    "#         model.add(Dense(2,kernel_initializer = keras.initializers.Constant(value=0.01)))\n",
    "#         model.add(Activation(\"softmax\"))\n",
    "    opt = Adam(lr=0.000001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model = Sequential()\n",
    "    #Hidden Layer\n",
    "    model.add(Dense(9, activation='relu', kernel_initializer=keras.initializers.Constant(value=0.01), input_dim=num_features))\n",
    "    #Output layer\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=keras.initializers.Constant(value=0.01)))\n",
    "    #model.add(Activation(\"softmax\"))\n",
    "    # Compile model\n",
    "    #print(train_y.values.astype(int))\n",
    "    model.compile(optimizer=opt,loss='binary_crossentropy', metrics =['accuracy'])\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "    model.fit(data_RFE,train_y.values.astype(int),validation_data=(valid_RFE, test['OS'].values.astype(int)),epochs =10000, verbose = 0, callbacks=[es])\n",
    "    #saved_model = load_model('best_model.h5')\n",
    "    # evaluate the model\n",
    "    _, train_acc = model.evaluate(data_RFE, train_y.values.astype(int), verbose=0)\n",
    "    _, test_acc = model.evaluate(valid_RFE, test['OS'].values.astype(int), verbose=0)\n",
    "    print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "    Y_pred=model.predict_classes(valid_RFE)\n",
    "    #print(Y_pred)\n",
    "    #print(test['OS'].values.astype(int))\n",
    "#         #print(y_test)http://localhost:8888/notebooks/ICH/ANN.ipynb#\n",
    "#         acc=metrics.accuracy_score(test['OS'].values.astype(int),Y_pred)\n",
    "#         print(\"accuracy score = \"+str(acc)) \n",
    "    Accuracy = np.append(Accuracy,test_acc)\n",
    "Accuracy = pd.DataFrame(data = Accuracy.reshape(1,5),columns = df.columns)\n",
    "df = df.append(Accuracy)\n",
    "#del Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['OS'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('ANN_4_accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "print(data_RFE.shape[0])\n",
    "background = data_RFE.columns[np.random.choice(data_RFE.shape[0], 59, replace=False)]\n",
    "\n",
    "# explain predictions of the model on three images\n",
    "e = shap.DeepExplainer(model, background)\n",
    "# ...or pass tensors directly\n",
    "# e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)\n",
    "shap_values = e.shap_values(valid_RFE[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df =pd.concat([df,df.iloc[:,1:].mean(axis=1)],axis = 1)\n",
    "df.columns = ['num_features','fold1','fold2','fold3','fol4','Average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('LR_accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr, _ = pearsonr(train['kurtosis'].astype(int), train['OS'].astype(int))\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr, _ = pearsonr(train['SecondAxis2'].astype(int), train['OS'].astype(int))\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(train['ThirdAxis1'].astype(int), train['OS'].astype(int))\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(train['Age'].astype(int), train['OS'].astype(int))\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import sklearn.svm as svm\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Y_pred)\n",
    "print(test['OS'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(test['OS'].values,Y_pred)\n",
    "# FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "# FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "# TP = np.diag(confusion_matrix)\n",
    "# TN = confusion_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "TN,FP,FN,TP = confusion_matrix.ravel()\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "#Precision\n",
    "PPV = TP/(TP+FP)\n",
    "\n",
    "print('Sensitivity ='+ str(TPR))\n",
    "print('Specificity = ' +str(TNR))\n",
    "print('Precision = '+str(PPV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "explainer = shap.LinearExplainer(svm, data_RFE, feature_dependence=\"independent\")\n",
    "shap_values = explainer.shap_values(data_RFE)\n",
    "shap.initjs()\n",
    "# plot the SHAP values for the Setosa output of the first instance\n",
    "shap.summary_plot(shap_values, data_RFE.iloc[:,:], feature_names=data_RFE.columns,show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
